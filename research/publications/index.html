<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Publications &middot; Prem Seetharaman
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <script src="/public/js/picturefill.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/wavesurfer.js/1.0.52/wavesurfer.min.js"></script>
  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <img style="border-radius: 50%; margin-left:10%; max-width:80%" src="/public/images/avatar.jpg">
      <h1>Prem Seetharaman</h1>
      <p class="lead"> I am a teaching fellow at Northwestern University. I recieved my PhD in 2019, advised by <a href="https://users.cs.northwestern.edu/~pardo/">Bryan Pardo</a>. The objective of my research is to create machines that can understand the auditory world. I work in computer audition, machine learning, and human computer interaction. </p>
    </div>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
        <a href="/">Home</a>
      </li>
      <li class="sidebar-nav-item">
        <a href="/research">Research</a>
      </li>
      <li class="sidebar-nav-item">
        <a href="/music">Music</a>
      </li>

      

      
      
        
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
            <li class="sidebar-nav-item">
              <a href="/notebooks/">Jupyter Notebooks and Lectures</a>
            </li>
          
        
      
        
          
            <li class="sidebar-nav-item active">
              <a href="/publications/">Publications</a>
            </li>
          
        
      
        
          
        
      
        
          
        
      

      <li class="sidebar-nav-item"><a href="/public/cv.pdf" target="_blank">CV</a></li>
    </ul>

  </div>
</div>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Publications</h1>
  <p><a href="https://scholar.google.com/citations?user=XHD-48cAAAAJ&amp;hl=en">Google scholar</a></p>

<p><strong>Thesis</strong></p>
<p class="bibliography"><p>
<a href="/public/papers/thesis.pdf">[pdf]</a>




<a href="/public/thesis">[demo]</a>


<span id="seetharaman2019bootstrappinglearning">Seetharaman, P. (2019). <i>Bootstrapping the Learning Process for Computer Audition</i> (PhD thesis). Northwestern University.</span></p></p>

<p><strong>Patents</strong></p>
<p class="bibliography"><p>




<span id="rafii2018audio">Rafii, Z., &amp; Seetharaman, P. (2018). Audio Identification Based on Data Structure.</span></p>
<p>




<span id="cremer2018automated">Cremer, M. K., Rafii, Z., Coover, R., &amp; Seetharaman, P. (2018). Automated Cover Song Identification.</span></p></p>

<p><strong>Refereed Journal Articles</strong></p>
<p class="bibliography"><p>

<a href="https://github.com/interactiveaudiolab/earthquakes">[code]</a>




<span id="tang2019automating">Tang, V., Seetharaman, P., Chao, K., Pardo, B., &amp; van der Lee, S. (2020). Automating the Detection of Dynamically Triggered Earthquakes via a Deep Metric Learning Algorithm. <i>Seismological Research Letters</i>, <i>(to appear)</i>.</span></p>
<p>
<a href="/public/papers/pardo_cartwright_seetharaman_kim_arts19.pdf">[pdf]</a>





<span id="pardo2019learning">Pardo, B., Cartwright, M., Seetharaman, P., &amp; Kim, B. (2019). Learning to Build Natural Audio Production Interfaces. In <i>Arts</i> (Vol. 8, p. 110). Multidisciplinary Digital Publishing Institute.</span></p>
<p>
<a href="/public/papers/humphrey_spm19.pdf">[pdf]</a>





<span id="humphrey2018introduction">Humphrey, E. J., Reddy, S., Seetharaman, P., Kumar, A., Bittner, R. M., Demetriou, A., … others. (2018). An Introduction to Signal Processing for Singing-Voice Analysis: High Notes in the Effort to Automate the Understanding of Vocals in Music. <i>IEEE Signal Processing Magazine</i>, <i>36</i>(1), 82–94.</span></p>
<p>
<a href="/public/papers/seetharaman_pardo_audealize_jaes.pdf">[pdf]</a>




<a href="https://audealize.appspot.com/">[demo]</a>


<span id="seetharaman2016audealize">Seetharaman, P., &amp; Pardo, B. (2016). Audealize: Crowdsourced Audio Production Tools. <i>Journal of the Audio Engineering Society</i>, <i>64</i>(9), 683–695.</span></p></p>

<p><strong>Refereed Conference Papers</strong></p>
<p class="bibliography"><p>
<a href="https://arxiv.org/pdf/1910.12626.pdf">[pdf]</a>





<span id="liu2019model">Liu, A., Seetharaman, P., &amp; Pardo, B. (2020). Model Selection for Deep Audio Source Separation via Clustering Analysis. <i>ArXiv Preprint ArXiv:1910.12626</i>.</span></p>
<p>
<a href="https://arxiv.org/pdf/1910.12621.pdf">[pdf]</a>





<span id="manilow2019simultaneous">Manilow, E., Seetharaman, P., &amp; Pardo, B. (2020). Simultaneous Separation and Transcription of Mixtures with Multiple Polyphonic and Percussive Instruments. <i>ArXiv Preprint ArXiv:1910.12621</i>.</span></p>
<p>
<a href="https://arxiv.org/pdf/1910.11133.pdf">[pdf]</a>





<span id="seetharaman2019bootstrapping">Seetharaman, P., Wichern, G., Roux, J. L., &amp; Pardo, B. (2020). Bootstrapping Deep Music Separation from Primitive Auditory Grouping Principles. <i>ArXiv Preprint ArXiv:1910.11133</i>.</span></p>
<p>
<a href="/public/papers/thesis.pdf">[pdf]</a>




<a href="/public/thesis">[demo]</a>


<span id="seetharaman2019bootstrappinglearning">Seetharaman, P. (2019). <i>Bootstrapping the Learning Process for Computer Audition</i> (PhD thesis). Northwestern University.</span></p>
<p>
<a href="/public/papers/seetharaman_voiceassist_chi19.pdf">[pdf]</a>





<span id="seetharaman2019voiceassist">Seetharaman, P., Mysore, G., Pardo, B., Smaragdis, P., &amp; Gomes, C. (2019). VoiceAssist: Guiding Users to High-Quality Voice Recordings. In <i>Proceedings of the SIGCHI Conference on Human Factors in Computing Systems.</i> ACM.</span></p>
<p>
<a href="/public/papers/manilow_wichern_seetharaman_le_roux_waspaa19.pdf">[pdf]</a>



<a href="https://www.slakh.com">[data]</a>



<span id="manilow2019cutting">Manilow, E., Wichern, G., Seetharaman, P., &amp; Roux, J. L. (2019). Cutting Music Source Separation Some Slakh: A Dataset to Study the Impact of Training Data Quality and Quantity. In <i>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</i>.</span></p>
<p>
<a href="/public/papers/pishdadian_kim_seetharaman_pardo_dcase2019.pdf">[pdf]</a>





<span id="pishdadian2019classifying">Pishdadian, F., Kim, B., Seetharaman, P., &amp; Pardo, B. (2019). Classifying Non-Speech Vocals: Deep vs Signal Processing Representations. <i>Proceedings of DCASE 2019</i>.</span></p>
<p>
<a href="/public/papers/seetharaman_bootstrapping_icassp19.pdf">[pdf]</a>





<span id="seetharaman2018bootstrapping">Seetharaman, P., Wichern, G., Roux, J. L., &amp; Pardo, B. (2019). Bootstrapping Single-Channel Source Separation via Unsupervised Spatial Clustering on Stereo Mixtures. In <i>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>.</span></p>
<p>
<a href="/public/papers/seetharaman_class_icassp19.pdf">[pdf]</a>





<span id="seetharaman2018class">Seetharaman, P., Wichern, G., Venkataramani, S., &amp; Roux, J. L. (2019). Class-Conditional Embeddings for Music Source Separation. In <i>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>.</span></p>
<p>
<a href="/public/papers/manilow_seetharaman_ismir18.pdf">[pdf]</a>


<a href="https://github.com/interactiveaudiolab/nussl">[code]</a>




<span id="manilow2018northwestern">Manilow, E., Seetharaman, P., &amp; Pardo, B. (2018). The Northwestern University Source Separation Library. In <i>Proceedings of the 19th International Society for Music Information Retrieval Conference</i>.</span></p>
<p>
<a href="/public/papers/seetharaman_mysore_icassp18.pdf">[pdf]</a>





<span id="seetharaman2018blind">Seetharaman, P., Mysore, G. J., Smaragdis, P., &amp; Pardo, B. (2018). Blind Estimation of the Speech Transmission Index for Speech Quality Prediction. In <i>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>.</span></p>
<p>
<a href="/public/papers/wilkins_seetharaman_ismir18.pdf">[pdf]</a>



<a href="https://zenodo.org/record/1193957">[data]</a>


<a href="https://interactiveaudiolab.github.io/demos/vocalset">[demo]</a>


<span id="wilkins2018vocalset">Wilkins, J., Seetharaman, P., Wahl, A., &amp; Pardo, B. (2018). VocalSet: A Singing Voice Dataset. In <i>Proceedings of the 19th International Society for Music Information Retrieval Conference</i>.</span></p>
<p>
<a href="public/papers/seetharaman_2dft_waspaa2017.pdf">[pdf]</a>




<a href="https://interactiveaudiolab.github.io/demos/2dft">[demo]</a>


<span id="seetharaman2017music">Seetharaman, P., Pishdadian, F., &amp; Pardo, B. (2017). Music/Voice Separation Using the 2D Fourier Transform. In <i>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</i>.</span></p>
<p>
<a href="/public/papers/manilow_seetharaman_pishdadian_waspaa2017.pdf">[pdf]</a>




<a href="https://interactiveaudiolab.github.io/demos/multicue">[demo]</a>


<span id="manilow2017predicting">Manilow, E., Seetharaman, P., Pishdadian, F., &amp; Pardo, B. (2017). Predicting Algorithm Efficacy for Adaptive Multi-Cue Source Separation. In <i>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</i>.</span></p>
<p>
<a href="/public/papers/seetharaman_rafii_icassp17.pdf">[pdf]</a>


<a href="https://github.com/pseeth/coversong_identification">[code]</a>




<span id="seetharaman2017cover">Seetharaman, P., &amp; Rafii, Z. (2017). Cover Song Identification with 2D Fourier Transform Sequences. In <i>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>.</span></p>
<p>
<a href="/public/papers/zheng_seetharaman_pardo_acmmm.pdf">[pdf]</a>



<a href="http://music.eecs.northwestern.edu/data/socialfx/">[data]</a>



<span id="zheng2016socialfx">Zheng, T., Seetharaman, P., &amp; Pardo, B. (2016). SocialFX: Studying a Crowdsourced Folksonomy of Audio Effects Terms. In <i>Proceedings of the 2016 ACM on Multimedia Conference</i> (pp. 182–186). ACM.</span></p>
<p>
<a href="/public/papers/seetharaman_pardo_ismir16.pdf">[pdf]</a>


<a href="https://github.com/interactiveaudiolab/separation_segmentation_ismir">[code]</a>




<span id="seetharaman2016simultaneous">Seetharaman, P., &amp; Pardo, B. (2016). Simultaneous Separation and Segmentation in Layered Music. In <i>Proceedings of the 17th International Society for Music Information Retrieval Conference</i> (pp. 495–502).</span></p>
<p>
<a href="/public/papers/seetharaman_pardo_acmmm14.pdf">[pdf]</a>





<span id="seetharaman2014crowdsourcing">Seetharaman, P., &amp; Pardo, B. (2014). Crowdsourcing a Reverberation Descriptor Map. In <i>Proceedings of the 22nd ACM international conference on Multimedia</i> (pp. 587–596). ACM.</span></p>
<p>
<a href="/public/papers/seetharaman_tarzia_aes12.pdf">[pdf]</a>





<span id="seetharaman2012hand">Seetharaman, P., &amp; Tarzia, S. P. (2012). The Hand Clap as an Impulse Source for Measuring Room Acoustics. In <i>Audio Engineering Society Convention 132</i>. Audio Engineering Society.</span></p></p>

<p><strong>Refereed Extended Abstracts</strong></p>
<p class="bibliography"><p>
<a href="/public/papers/donovan_seetharaman_web_audio.pdf">[pdf]</a>


<a href="https://interactiveaudiolab.github.io/audealize_api">[code]</a>




<span id="donovan2017web">Donovan, M., Seetharaman, P., &amp; Pardo, B. (2017). A Web Audio Node for the Fast Creation of Natural Language Interfaces for Audio Production.</span></p>
<p>
<a href="/public/papers/seetharaman_pardo_td_acmmm14.pdf">[pdf]</a>





<span id="seetharaman2014reverbalize">Seetharaman, P., &amp; Pardo, B. (2014). Reverbalize: A Crowdsourced Reverberation Controller. In <i>Proceedings of the 22nd ACM international conference on Multimedia</i> (pp. 739–740). ACM.</span></p></p>

<p><strong>Non-refereed Abstracts</strong></p>
<p class="bibliography"><p>




<span id="chao2018automatic">Chao, K., Seetharaman, P., Tang, V., Pardo, B. A., &amp; Van der Lee, S. (2018). Automatic classification of triggered tectonic tremor with deep learning. In <i>AGU Fall Meeting Abstracts</i>.</span></p>
<p>




<span id="tang2018siamese">Tang, V., Seetharaman, P., Chao, K., Pardo, B. A., &amp; van der Lee, S. (2018). Siamese networks for triggered earthquakes detection. In <i>AGU Fall Meeting Abstracts</i>.</span></p></p>

</div>

    </div>

  </body>
</html>
