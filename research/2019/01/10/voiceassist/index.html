<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      VoiceAssist - guiding users to high-quality voice recordings &middot; Prem Seetharaman
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <script src="/public/js/picturefill.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/wavesurfer.js/1.0.52/wavesurfer.min.js"></script>
  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <img style="border-radius: 50%; margin-left:10%; max-width:80%" src="/public/images/avatar.jpg">
      <h1>Prem Seetharaman</h1>
      <p class="lead"> I am a PhD candidate at Northwestern University in the <a href="http://music.cs.northwestern.edu">Interactive Audio Lab</a>, under Prof. Bryan Pardo. The objective of my research is to create machines that can understand the auditory world like humans can. I work in machine learning, music information retrieval, audio source separation, music structure and similarity, acoustics, and human computer interaction. </p>
    </div>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
        <a href="/">Home</a>
      </li>
      <li class="sidebar-nav-item">
        <a href="/research">Research</a>
      </li>
      <li class="sidebar-nav-item">
        <a href="/music">Music</a>
      </li>

      

      
      
        
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
            <li class="sidebar-nav-item">
              <a href="/notebooks/">Jupyter Notebooks and Lectures</a>
            </li>
          
        
      
        
          
            <li class="sidebar-nav-item">
              <a href="/publications/">Publications</a>
            </li>
          
        
      
        
          
        
      
        
          
        
      

      <li class="sidebar-nav-item"><a href="/public/cv.pdf" target="_blank">CV</a></li>
    </ul>

  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">VoiceAssist - guiding users to high-quality voice recordings</h1>
  <span class="post-date">10 Jan 2019</span>
  <p><img alt="test" class="thumbnail-image" src="/generated/voiceassist/voiceassist-800by341-6008be.png" srcset="/generated/voiceassist/voiceassist-400by171-6008be.png 400w, /generated/voiceassist/voiceassist-600by256-6008be.png 600w, /generated/voiceassist/voiceassist-800by341-6008be.png 800w, /generated/voiceassist/voiceassist-1000by426-6008be.png 1000w"></p>

<p>Voice recording is a challenging task with many pitfalls due to sub-par recording environments, mistakes in recording setup, microphone quality, etc. Newcomers to voice recording often have difficulty recording their voice, leading to recordings with low sound quality. Many amateur recordings of poor quality have two key problems: too much reverberation (echo), and too much background noise  (e.g. fans, electronics, street noise). We present VoiceAssist, a system that helps inexperienced users produce high quality recordings by providing real-time visual feedback on audio quality.</p>

<!--more-->

<p>We integrate modern audio quality measures into an interactive human-machine feedback loop, so that the audio quality can be maximized at capture-time. We demonstrate the utility of this feedback for improving the recording quality with a user study. When presented with visual feedback about recording quality, users produced recordings that were strongly preferred by third-party listeners, when compared to recordings made without this feedback.</p>

<!-- {::nomarkdown}<img alt="test" class="thumbnail-image" src="/generated/voiceassist/jnd-800by280-368518.png" srcset="/generated/voiceassist/jnd-400by140-368518.png 400w, /generated/voiceassist/jnd-600by210-368518.png 600w, /generated/voiceassist/jnd-800by280-368518.png 800w, /generated/voiceassist/jnd-1000by350-368518.png 1000w">{:/nomarkdown} -->

<p>This work was done in colloboration with Adobe Research.</p>

<ul>
  <li><a href="/public/papers/seetharaman_voiceassist_chi19.pdf">CHI ‘19 Paper</a></li>
  <li><a href="/public/papers/seetharaman_mysore_icassp18.pdf">ICASSP ‘18 Paper</a></li>
</ul>


</div>

<!--
<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/research/2019/02/10/bootstrapping-spatial/">
            Bootstrapping speech separation from unsupervised spatial separation
            <small>10 Feb 2019</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/research/2017/10/15/waspaa/">
            Adaptive multi-cue audio source separation
            <small>15 Oct 2017</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/research/2016/12/01/coversong/">
            Cover song identification with 2D Fourier transform sequences
            <small>01 Dec 2016</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>
-->

    </div>

  </body>
</html>
